{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc618420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "import boto3\n",
    "import os\n",
    "import pyart\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import imageio\n",
    "\n",
    "import osmnx as ox\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "from math import cos, radians\n",
    "import numpy as np\n",
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba68786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking prefix: 2024/08/17/KRTX/\n",
      "Checking prefix: 2024/08/18/KRTX/\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "station = 'KRTX'\n",
    "start_time = datetime(2024, 8, 17, 22, 0)\n",
    "end_time = datetime(2024, 8, 18, 3, 0)\n",
    "output_dir = './radar_files'\n",
    "desired_fields = ['reflectivity', 'velocity', 'cross_correlation_ratio']\n",
    "\n",
    "# --- Setup ---\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "bucket = 'noaa-nexrad-level2'\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days) + 1):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "def download_radar_files(station, start_time, end_time):\n",
    "    files = []\n",
    "    start_date = start_time.date()\n",
    "    end_date = end_time.date()\n",
    "\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        prefix = f\"{single_date:%Y/%m/%d}/{station}/\"\n",
    "        print(f\"Checking prefix: {prefix}\")\n",
    "\n",
    "        response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "        if 'Contents' in response:\n",
    "            for obj in response['Contents']:\n",
    "                key = obj['Key']\n",
    "                basename = os.path.basename(key)\n",
    "                try:\n",
    "                    # Parse time from filename, e.g. KRTX20230818_0104_V06\n",
    "                    file_time = datetime.strptime(basename[4:17], \"%Y%m%d_%H%M\")\n",
    "                    if start_time <= file_time <= end_time:\n",
    "                        local_path = os.path.join(output_dir, basename)\n",
    "                        if not os.path.exists(local_path):\n",
    "                            print(f\"Downloading {basename}\")\n",
    "                            s3.download_file(bucket, key, local_path)\n",
    "                        files.append(local_path)\n",
    "                except Exception as e:\n",
    "                    # skip files with unexpected naming\n",
    "                    continue\n",
    "    return sorted(files)\n",
    "\n",
    "# --- Run ---\n",
    "files = download_radar_files(station, start_time, end_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "022f7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gridlines(ax, extent, spacing_lat=None, spacing_lon=None):\n",
    "    lon_min, lon_max, lat_min, lat_max = extent\n",
    "    if spacing_lat is None:\n",
    "        spacing_lat = max((lat_max - lat_min) / 5, 0.01) \n",
    "    if spacing_lon is None:\n",
    "        spacing_lon = max((lon_max - lon_min) / 5, 0.01)\n",
    "\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "\n",
    "    import matplotlib.ticker as mticker\n",
    "    import numpy as np\n",
    "    gl.xlocator = mticker.FixedLocator(np.arange(lon_min, lon_max + spacing_lon, spacing_lon))\n",
    "    gl.ylocator = mticker.FixedLocator(np.arange(lat_min, lat_max + spacing_lat, spacing_lat))\n",
    "\n",
    "    gl.xlabel_style = {'size': 8}\n",
    "    gl.ylabel_style = {'size': 8}\n",
    "\n",
    "def domain_size_km(lat_min, lat_max, lon_min, lon_max):\n",
    "    \"\"\"Calculate approximate max dimension of domain in km.\"\"\"\n",
    "    avg_lat = (lat_min + lat_max) / 2\n",
    "    lat_km = (lat_max - lat_min) * 111\n",
    "    lon_km = (lon_max - lon_min) * 111 * cos(radians(avg_lat))\n",
    "    return max(lat_km, lon_km)\n",
    "\n",
    "def download_osm_features(center_lat, center_lon, dist_m, lat_min, lat_max, lon_min, lon_max):\n",
    "    size_km = domain_size_km(lat_min, lat_max, lon_min, lon_max)\n",
    "    print('Size: ', size_km, 'km')\n",
    "    \n",
    "    # Thresholds (example, tweak to your liking)\n",
    "    # Smaller size -> more detail\n",
    "    road_detail_levels = [\n",
    "        (5, [\"motorway\", \"trunk\", \"primary\", \"secondary\", \"tertiary\", \"unclassified\", \"residential\", \"service\", \"track\", \"path\"]),\n",
    "        (20, [\"motorway\", \"trunk\", \"primary\", \"secondary\", \"tertiary\", \"unclassified\", \"residential\"]),\n",
    "        (50, [\"motorway\", \"trunk\", \"primary\", \"secondary\"]),\n",
    "        (200, [\"motorway\", \"trunk\", \"primary\"]),\n",
    "        (500, [\"motorway\", \"trunk\"]),\n",
    "        (float('inf'), [\"motorway\"])\n",
    "    ]\n",
    "\n",
    "    city_detail_levels = [\n",
    "        (50, [\"city\", \"town\", \"village\", \"hamlet\"]),\n",
    "        (100, [\"city\", \"town\", \"village\"]),\n",
    "        (150, [\"city\", \"town\"]),\n",
    "        (200, [\"city\"])\n",
    "    ]\n",
    "\n",
    "    water_detail_levels = [\n",
    "        (5, {\"natural\": [\"water\"], \"waterway\": [\"river\", \"stream\", \"canal\", \"drain\", \"ditch\"]}),\n",
    "        (20, {\"natural\": [\"water\"], \"waterway\": [\"river\", \"stream\", \"canal\"]}),\n",
    "        (500, {\"natural\": [\"water\"], \"waterway\": [\"river\"]}),\n",
    "        (float('inf'), {\"natural\": [\"water\"]})\n",
    "    ]\n",
    "\n",
    "    def select_level(levels, size):\n",
    "        for threshold, val in levels:\n",
    "            if size <= threshold:\n",
    "                return val\n",
    "        return levels[-1][1]\n",
    "\n",
    "    # Select tags based on domain size\n",
    "    highway_tags = select_level(road_detail_levels, size_km)\n",
    "    city_tags = select_level(city_detail_levels, size_km)\n",
    "    water_tags = select_level(water_detail_levels, size_km)\n",
    "\n",
    "    # Download roads\n",
    "    print(\"Downloading roads with tags:\", highway_tags)\n",
    "    try:\n",
    "        roads = ox.features.features_from_point(\n",
    "            (center_lat, center_lon),\n",
    "            tags={\"highway\": highway_tags},\n",
    "            dist=dist_m\n",
    "        )\n",
    "        roads = roads[roads.geometry.type.isin([\"LineString\", \"MultiLineString\"])]\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to download roads: {e}\")\n",
    "        roads = None\n",
    "\n",
    "    # Download water\n",
    "    print(\"Downloading water features with tags:\", water_tags)\n",
    "    try:\n",
    "        water = ox.features.features_from_point(\n",
    "            (center_lat, center_lon),\n",
    "            tags=water_tags,\n",
    "            dist=dist_m\n",
    "        )\n",
    "        water = water[water.geometry.type.isin([\"Polygon\", \"MultiPolygon\", \"LineString\", \"MultiLineString\"])]\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to download water features: {e}\")\n",
    "        water = None\n",
    "\n",
    "    # Download cities\n",
    "    print(\"Downloading cities with tags:\", city_tags)\n",
    "    try:\n",
    "        cities = ox.features.features_from_point(\n",
    "            (center_lat, center_lon),\n",
    "            tags={\"place\": city_tags},\n",
    "            dist=dist_m\n",
    "        )\n",
    "        cities = cities[cities.geometry.type == \"Point\"]\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to download cities: {e}\")\n",
    "        cities = None\n",
    "\n",
    "    return roads, water, cities\n",
    "\n",
    "    \n",
    "def compute_osm_query_center_and_radius(lat_min, lat_max, lon_min, lon_max, lat_rate, lon_rate, n_frames):\n",
    "    # Compute full domain bounds after all shifts\n",
    "    lat_max_final = lat_max + (n_frames - 1) * lat_rate\n",
    "    lat_min_final = lat_min + (n_frames - 1) * lat_rate\n",
    "    lon_max_final = lon_max + (n_frames - 1) * lon_rate\n",
    "    lon_min_final = lon_min + (n_frames - 1) * lon_rate\n",
    "\n",
    "    overall_lat_min = min(lat_min, lat_min_final)\n",
    "    overall_lat_max = max(lat_max, lat_max_final)\n",
    "    overall_lon_min = min(lon_min, lon_min_final)\n",
    "    overall_lon_max = max(lon_max, lon_max_final)\n",
    "\n",
    "    center_lat = (overall_lat_min + overall_lat_max) / 2\n",
    "    center_lon = (overall_lon_min + overall_lon_max) / 2\n",
    "\n",
    "    size_km = domain_size_km(overall_lat_min, overall_lat_max, overall_lon_min, overall_lon_max)\n",
    "    # Add some padding to dist_m to cover edges well\n",
    "    dist_m = (size_km / 2) * 1000 * 1.2  # half diagonal approx * padding\n",
    "\n",
    "    return center_lat, center_lon, dist_m, overall_lat_min, overall_lat_max, overall_lon_min, overall_lon_max\n",
    "\n",
    "\n",
    "def plot_field_sequence(\n",
    "    data_dir: str,\n",
    "    output_dir: str,\n",
    "    field: str,\n",
    "    start_time: datetime,\n",
    "    end_time: datetime,\n",
    "    lat_min: float = None,\n",
    "    lat_max: float = None,\n",
    "    lon_min: float = None,\n",
    "    lon_max: float = None,\n",
    "    lat_rate: float = 0.0,\n",
    "    lon_rate: float = 0.0,\n",
    "    dpi: int = 150,\n",
    "    figsize: tuple = (6, 6),\n",
    "    cmap: str = 'NWSRef',\n",
    "    vmin: float = None,\n",
    "    vmax: float = None,\n",
    "    map_detail: str = '10m',\n",
    "    features: bool = True,\n",
    "    sweep: int = 0\n",
    "):\n",
    "    frames_dir = os.path.join(output_dir, 'frames')\n",
    "    os.makedirs(frames_dir, exist_ok=True)\n",
    "\n",
    "    all_files = sorted(glob.glob(os.path.join(data_dir, '*')))\n",
    "    def file_time(fn):\n",
    "        s = os.path.basename(fn)\n",
    "        return datetime.strptime(s[4:17], '%Y%m%d_%H%M')\n",
    "    files = [f for f in all_files if (start_time <= file_time(f) <= end_time) and f.endswith('_V06')]\n",
    "    files.sort(key=file_time)\n",
    "\n",
    "    if not files:\n",
    "        print(f\"⚠️  No files found between {start_time} and {end_time} in {data_dir}\")\n",
    "        return\n",
    "\n",
    "    if lat_min is None or lon_min is None:\n",
    "        r0 = pyart.io.read(files[0])\n",
    "        lats = r0.gate_latitude['data']\n",
    "        lons = r0.gate_longitude['data']\n",
    "        lat_min, lat_max = float(lats.min()), float(lats.max())\n",
    "        lon_min, lon_max = float(lons.min()), float(lons.max())\n",
    "        del r0\n",
    "\n",
    "    center_lat, center_lon, dist_m, overall_lat_min, overall_lat_max, overall_lon_min, overall_lon_max = compute_osm_query_center_and_radius(\n",
    "        lat_min, lat_max, lon_min, lon_max, lat_rate, lon_rate, len(files)\n",
    "    )\n",
    "\n",
    "    if features:\n",
    "        road_gdf, water_gdf, city_gdf = download_osm_features(\n",
    "            center_lat, center_lon, dist_m, overall_lat_min, overall_lat_max, overall_lon_min, overall_lon_max\n",
    "        )\n",
    "    else:\n",
    "        road_gdf, water_gdf, city_gdf = None, None, None\n",
    "\n",
    "    domain_km = domain_size_km(overall_lat_min, overall_lat_max, overall_lon_min, overall_lon_max)\n",
    "\n",
    "    frame_files = []\n",
    "    for i, fn in enumerate(files):\n",
    "        t = file_time(fn)\n",
    "        print(t)\n",
    "        c_lat_min = lat_min + i * lat_rate\n",
    "        c_lat_max = lat_max + i * lat_rate\n",
    "        c_lon_min = lon_min + i * lon_rate\n",
    "        c_lon_max = lon_max + i * lon_rate\n",
    "        extent = [c_lon_min, c_lon_max, c_lat_min, c_lat_max]\n",
    "\n",
    "        try:\n",
    "            radar = pyart.io.read(fn)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Could not read {os.path.basename(fn)}: {e}\")\n",
    "            continue\n",
    "        if field not in radar.fields:\n",
    "            print(f\"⚠️  {field} missing in {os.path.basename(fn)}, skipping\")\n",
    "            continue\n",
    "\n",
    "        \n",
    "\n",
    "        if field in radar.fields:\n",
    "            field_data = radar.fields[field]['data']\n",
    "            if isinstance(field_data, ma.MaskedArray):\n",
    "                print(f\"{field} frame {i}: min={field_data.min()}, max={field_data.max()}, masked={field_data.mask.sum()} / {field_data.size}\")\n",
    "            else:\n",
    "                print(f\"{field} frame {i}: min={np.min(field_data)}, max={np.max(field_data)}\")\n",
    "\n",
    "        fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "        ax = plt.subplot(projection=ccrs.PlateCarree())\n",
    "        ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "        # Add map features\n",
    "        ax.add_feature(cfeature.COASTLINE.with_scale(map_detail))\n",
    "        ax.add_feature(cfeature.BORDERS.with_scale(map_detail))\n",
    "        ax.add_feature(cfeature.STATES.with_scale(map_detail))\n",
    "\n",
    "        # Plot roads\n",
    "        if road_gdf is not None:\n",
    "            road_gdf.plot(ax=ax, color='dimgray', linewidth=0.4, transform=ccrs.PlateCarree(), zorder=3)\n",
    "\n",
    "        # Plot water\n",
    "        if water_gdf is not None:\n",
    "            water_gdf.plot(ax=ax, color='dodgerblue', linewidth=0.6, alpha=0.6, transform=ccrs.PlateCarree(), zorder=2)\n",
    "\n",
    "        if city_gdf is not None:\n",
    "            # Marker size scales with zoom: larger markers for small domains\n",
    "            city_size = 10 if domain_km <= 30 else 4\n",
    "            city_gdf.plot(ax=ax, color='black', markersize=city_size, transform=ccrs.PlateCarree(), zorder=4)\n",
    "\n",
    "            # Filter cities within current frame extent\n",
    "            lon_min, lon_max, lat_min, lat_max = extent\n",
    "            visible_cities = city_gdf.cx[lon_min:lon_max, lat_min:lat_max]\n",
    "\n",
    "            # Always label cities within current extent\n",
    "            for _, row in visible_cities.iterrows():\n",
    "                name = row.get('name')\n",
    "                if name:\n",
    "                    ax.text(\n",
    "                        row.geometry.x,\n",
    "                        row.geometry.y,\n",
    "                        name,\n",
    "                        transform=ccrs.PlateCarree(),\n",
    "                        fontsize=7 if domain_km <= 30 else 5,\n",
    "                        ha='left',\n",
    "                        va='bottom',\n",
    "                        color='black',\n",
    "                        zorder=5\n",
    "                    )\n",
    "\n",
    "        # Plot radar data\n",
    "        disp = pyart.graph.RadarMapDisplay(radar)\n",
    "        disp.plot_ppi_map(\n",
    "            field, sweep,\n",
    "            ax=ax,\n",
    "            vmin=vmin, vmax=vmax, cmap=cmap,\n",
    "            lat_lines=None, lon_lines=None,\n",
    "            projection=ccrs.PlateCarree(),\n",
    "            min_lat=c_lat_min, max_lat=c_lat_max,\n",
    "            min_lon=c_lon_min, max_lon=c_lon_max,\n",
    "            resolution=map_detail,\n",
    "        )\n",
    "\n",
    "        # Add gridlines\n",
    "        add_gridlines(ax, extent)\n",
    "\n",
    "        plt.title(f\"{field} @ {t:%Y-%m-%d %H:%M} UTC\", fontsize=10)\n",
    "        out_png = os.path.join(frames_dir, f\"frame_{i:03d}.png\")\n",
    "        plt.savefig(out_png, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "        frame_files.append(out_png)\n",
    "\n",
    "    if not frame_files:\n",
    "        print(f\"⚠️  All files in the window were missing field `{field}`. No frames to stitch.\")\n",
    "        return\n",
    "\n",
    "    imgs = [imageio.imread(fn) for fn in frame_files]\n",
    "    gif_path = os.path.join(output_dir, f\"{field}_{start_time:%H%M}_{end_time:%H%M}.gif\")\n",
    "    imageio.mimsave(gif_path, imgs, fps=4)\n",
    "    print(f\"✅  Saved {len(frame_files)} frames + GIF → {gif_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d46a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  59.122932520638514 km\n",
      "Downloading roads with tags: ['motorway', 'trunk', 'primary']\n",
      "Downloading water features with tags: {'natural': ['water'], 'waterway': ['river']}\n",
      "Downloading cities with tags: ['city', 'town', 'village']\n",
      "2024-08-17 22:03:00\n",
      "cross_correlation_ratio frame 0: min=0.2083333283662796, max=1.0516666173934937, masked=15069907 / 16488000\n",
      "2024-08-17 22:08:00\n",
      "cross_correlation_ratio frame 1: min=0.2083333283662796, max=1.0516666173934937, masked=15050189 / 16488000\n",
      "2024-08-17 22:13:00\n",
      "cross_correlation_ratio frame 2: min=0.2083333283662796, max=1.0516666173934937, masked=15028268 / 16488000\n",
      "2024-08-17 22:18:00\n",
      "cross_correlation_ratio frame 3: min=0.2083333283662796, max=1.0516666173934937, masked=15009711 / 16488000\n",
      "2024-08-17 22:23:00\n",
      "cross_correlation_ratio frame 4: min=0.2083333283662796, max=1.0516666173934937, masked=14986982 / 16488000\n",
      "2024-08-17 22:28:00\n",
      "cross_correlation_ratio frame 5: min=0.2083333283662796, max=1.0516666173934937, masked=14965212 / 16488000\n",
      "2024-08-17 22:33:00\n",
      "cross_correlation_ratio frame 6: min=0.2083333283662796, max=1.0516666173934937, masked=14949276 / 16488000\n",
      "2024-08-17 22:38:00\n",
      "cross_correlation_ratio frame 7: min=0.2083333283662796, max=1.0516666173934937, masked=14295583 / 15828480\n",
      "2024-08-17 22:43:00\n",
      "cross_correlation_ratio frame 8: min=0.2083333283662796, max=1.0516666173934937, masked=14906318 / 16488000\n",
      "2024-08-17 22:47:00\n",
      "cross_correlation_ratio frame 9: min=0.2083333283662796, max=1.0516666173934937, masked=15522882 / 17147520\n",
      "2024-08-17 22:52:00\n",
      "cross_correlation_ratio frame 10: min=0.2083333283662796, max=1.0516666173934937, masked=14867348 / 16488000\n",
      "2024-08-17 22:57:00\n",
      "cross_correlation_ratio frame 11: min=0.2083333283662796, max=1.0516666173934937, masked=15461608 / 17147520\n",
      "2024-08-17 23:02:00\n",
      "cross_correlation_ratio frame 12: min=0.2083333283662796, max=1.0516666173934937, masked=16061159 / 17807040\n",
      "2024-08-17 23:07:00\n",
      "cross_correlation_ratio frame 13: min=0.2083333283662796, max=1.0516666173934937, masked=16020553 / 17807040\n",
      "2024-08-17 23:13:00\n",
      "cross_correlation_ratio frame 14: min=0.2083333283662796, max=1.0516666173934937, masked=15979715 / 17807040\n",
      "2024-08-17 23:18:00\n",
      "cross_correlation_ratio frame 15: min=0.2083333283662796, max=1.0516666173934937, masked=15953090 / 17807040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_11768\\963342884.py:284: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  imgs = [imageio.imread(fn) for fn in frame_files]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved 16 frames + GIF → ./radar_animations/tor/correlation\\cross_correlation_ratio_2200_2320.gif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for field, cmap, vmin, vmax, folder, sweep in zip(['reflectivity', 'velocity', 'cross_correlation_ratio'], ['pyart_NWSRef', 'pyart_NWSVel', 'pyart_Carbone42'], [-20, -30, 0], [75, 30, 1], ['./radar_animations/tor/reflectivity', './radar_animations/tor/velocity', './radar_animations/tor/correlation'], [0, 1, 0]):\n",
    "    if field == 'cross_correlation_ratio':\n",
    "        plot_field_sequence(\n",
    "            data_dir   = './radar_files',\n",
    "            output_dir = folder,\n",
    "            field      = field,\n",
    "            start_time = datetime(2024,8,17,22,00),\n",
    "            end_time   = datetime(2024,8,17,23,20),\n",
    "            lat_min    = 44.5,\n",
    "            lat_max    = 45,\n",
    "            lon_min    = -122.5,\n",
    "            lon_max    = -121.75,\n",
    "            lon_rate   = 0,\n",
    "            cmap       = cmap,\n",
    "            vmin       = vmin,\n",
    "            vmax       = vmax,\n",
    "            features = True,\n",
    "            sweep = sweep\n",
    "        )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcs2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
